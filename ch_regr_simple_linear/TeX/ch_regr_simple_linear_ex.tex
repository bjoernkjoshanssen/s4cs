\section{Exercises}

% 1
\eoce{\qt{Extreme correlations}
	For a data set $(x_i,y_i)$, $1\le i \le n$, recall the correlation coefficient
	\[
		r = \frac{\sum (x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum_{i=1}^n (x_i-\overline x)^2}\sqrt{\sum_{i=1}^n (y_i-\overline y)^2}}.
	\]
	Give specific numerical examples of observations with
	\begin{parts}
		\item 
			$r = 1$,
		\item
			$r = 0$,
		\item
			$r = -1$.
	\end{parts}
	\footnote{
		By ``specific numerical'' is meant that, for instance, $\{(1,2),(0,-3),(0,0)\}$ could be a possible answer---although it will be wrong as $r$ will not be exactly 0, 1 or -1 for this particular choice!
	}
}{}

% 2
\eoce{\qt{Cauchy-Schwarz}
	Let $u_1, u_2, \dots, u_n$ and $v_1, v_2, \dots, v_n$ be real numbers.
	\begin{parts}
		\item 
			Rearrange the terms in $(u_1 x + v_1)^2 + (u_2 x + v_2)^2 + \dots + (u_n x + v_n)^2$ to obtain a quadratic polynomial $a x^2+b x+c$ in $x$.
		\item
			Note that the polynomial in part a has at most one real root and therefore that its discriminant $b^2-4ac$ is at most zero.
			Calculate this discriminant to conclude that
			$\left(\sum_{i=1}^n u_i v_i \right)^2 \le \left(\sum_{i=1}^n u_i^2\right) \left(\sum_{i=1}^n v_i^2\right)$.
			This inequality (and its various generalizations) is known as the \textit{Cauchy-Schwarz inequality}.
	\end{parts}
}{}

% 3
\eoce{\qt{Theory of extreme correlations}
	Let $(x_1, y_1), (x_2, y_2), \dots (x_n, y_n)$ be observations.
	\begin{parts}
		\item 
			Show that 
			\[
				\frac{1}{n-1} \sum_{i=1}^n \frac{x_i - \bar{x}}{s_x} \frac{y_i - \bar{y}}{s_y}
				= \frac{\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2} \sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}}
			\]
			Conclude that the term on the right is an equivalent formula for $r$.
		\item
			Apply the Cauchy-Schwarz inequality to $\left|\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y}) \right|$
			to conclude that $|r| \le 1$ and therefore that $-1 \le r \le 1$.
	\end{parts}
}{}

\eoce{\qt{Calculus on the $F$ distribution}
The $F$ distribution with degrees of freedom $d_1=d_2=1$ has the pdf
\[
f(x)=\frac{\sqrt{x/(x+1)^2}}{x B(1/2,1/2)}
\]
where $B(\alpha,\beta)=\Gamma(\alpha)\Gamma(\beta)/\Gamma(\alpha+\beta)$, $\Gamma(1/2)=\sqrt\pi$, and the formula $\Gamma(n)=(n-1)!$ for $n\ge 1$ holds.
Use your calculus knowledge to demonstrate that
\[
\int_0^{\infty} f(x)\,dx = 1.
\]
% Solution: it follows from (i)
% \[
% \int_0^\infty \frac{dx}{(x+1)\sqrt x} = \pi
% \]
% using the substitution $u=\sqrt x$ and (ii) $B(1/2,1/2)=\frac{\sqrt\pi \cdot \sqrt\pi}{(1-1)!} = \pi$.
}{}

\eoce{\qt{Calculus on the $F$ distribution II}
The $F$ distribution with degrees of freedom $d_1=1$ and $d_2=2$ has the pdf
\[
f(x)=\frac{\sqrt{4x/(x+2)^3}}{x B(1/2,1)}.
\]
Use your calculus knowledge to demonstrate that
\[
\int_0^{\infty} f(x)\,dx = 1.
\]
}{}

\eoce{\qt{Functional correlation}
	For a data set $(x_i,y_i)$, $1\le i \le n$, recall the correlation coefficient
	\[
		r = \frac{\sum (x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum_{i=1}^n (x_i-\overline x)^2}\sqrt{\sum_{i=1}^n (y_i-\overline y)^2}}.
	\]
	Find $r$ as a function of $y$, $r(y)$, for the data set $\{(1,0), (2,0), (3,y)\}$, and graph it.
}{}

\eoce{\qt{Extreme correlations II}
	For a data set $(x_i,y_i)$, $1\le i \le n$, recall the correlation coefficient
	\[
		r = \frac{\sum (x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum_{i=1}^n (x_i-\overline x)^2}\sqrt{\sum_{i=1}^n (y_i-\overline y)^2}}.
	\]
	Give a specific numerical example of $n$ distinct observations for which $r$ is undefined.
}{}

\eoce{\qt{Functional correlation II}
	For a data set $(x_i,y_i)$, $1\le i \le n$, recall the correlation coefficient
	\[
		r = \frac{\sum (x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum_{i=1}^n (x_i-\overline x)^2}\sqrt{\sum_{i=1}^n (y_i-\overline y)^2}}.
	\]
	Find $r$ as a function of $y$, $r(y)$, for the data set $\{(1,0), (1,1), (2,y)\}$, and graph it.
}{}


\eoce{\qt{Functional correlation III}
	For a data set $(x_i,y_i)$, $1\le i \le n$, recall the correlation coefficient
	\[
		r = \frac{\sum (x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum_{i=1}^n (x_i-\overline x)^2}\sqrt{\sum_{i=1}^n (y_i-\overline y)^2}}.
	\]
	Find $r$ as a function of $y$, $r(y)$, for the data set $\{(-1,0), (0,0), (1,y)\}$, and graph it.
}{}

\eoce{\qt{Functional correlation IV}
	For a data set $(x_i,y_i)$, $1\le i \le n$, recall the correlation coefficient
	\[
		r = \frac{\sum (x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum_{i=1}^n (x_i-\overline x)^2}\sqrt{\sum_{i=1}^n (y_i-\overline y)^2}}.
	\]
	Find $r$ as a function of $y$, $r(y)$, for the data set $\{(0,y), (y,0), (0,1)\}$, and graph it.
}{}

\eoce{\qt{Spreadsheet for Isak}
How many goals may we expect to be scored by Alexander Isak during the 2025--2026 Premier League season?
Construct a prediction interval.
}{}

\eoce{\qt{Spreadsheet for Salah}
How many goals may we expect to be scored by Mohamed Salah during the 2025--2026 Premier League season?
Construct a prediction interval by completing a spreadsheet like the one at \href{https://docs.google.com/spreadsheets/d/13Rvset_K3SSyru6MohnliE0Bx9wqInj4s0KHK-108kc/edit?usp=sharing}{this link}.
You can find Salah's goal stats \href{https://www.premierleague.com/en/players/118748/mohamed-salah/stats}{here}.
Use at least the last three seasons' numbers (2022--2023, 2023--2024, and 2024--2025).
}{}

\eoce{\qt{High goal correlation}
In the spreadsheet at \href{https://docs.google.com/spreadsheets/d/1CkDQoYrNkoMpplnHq42koLbCEqOqIdbmNevUtlSPV0g/edit?usp=sharing}{this link}
which player should be removed in order to make the correlation between goals in the 2023--2024 season
and goals in the 2024--2025 season as \emph{high} as possible?
}{}

\eoce{\qt{Low goal correlation}
In the spreadsheet at \href{https://docs.google.com/spreadsheets/d/1CkDQoYrNkoMpplnHq42koLbCEqOqIdbmNevUtlSPV0g/edit?usp=sharing}{this link}
which player should be removed in order to make the correlation between goals in the 2023--2024 season
and goals in the 2024--2025 season as \emph{low} as possible?
}{}

\eoce{\qt{Slope greater than intercept}
It is of course easy to give an example of a straight line $y=mx+b$ where the slope $m$ is greater than the $y$-intercept $b$.
Do something slightly harder: give an explicit example of points $(x_1,y_1),\dots,(x_n,y_n)$ such that
for the calculate regression line $y=b_0+b_1x$ we have $b_1>b_0$.
}

\eoce{\qt{Intercept greater than slope}
It is of course easy to give an example of a straight line $y=mx+b$ where the slope $m$ is less than the $y$-intercept $b$.
Do something slightly harder: give an explicit example of points $(x_1,y_1),\dots,(x_n,y_n)$ such that
for the calculate regression line $y=b_0+b_1x$ we have $b_1<b_0$.
}

\eoce{\qt{Average algebra}
Recall the average notation: $\overline{xy}=\frac1n\sum_{i=1}^n x_iy_i$, $\overline{x^2}=\frac1n\sum_{i=1}^n x_i^2$, etc.
Find an example of numbers $x_1,\dots,x_n$ such that $\overline {x^3} \ne (\overline{x})^3$.
}

\eoce{\qt{Average algebra II}
Recall the average notation: $\overline{xy}=\frac1n\sum_{i=1}^n x_iy_i$, $\overline{x^2}=\frac1n\sum_{i=1}^n x_i^2$, etc.
Find an example of points $(x_1,y_1),\dots,(x_n,y_n)$ such that $\overline {xy} \cdot \overline{y} \ne \overline{x}\cdot \overline{y^2}$.
}

\eoce{\qt{From F to B}
Suppose $X$ has the F distribution with degrees of freedom 1 and 1.
Find the pdf of $Y=\frac{X}{X+1}$ and compare it to a beta distribution pdf.
}

\eoce{\qt{From F to B II}
Suppose $X$ has the F distribution with degrees of freedom 1 and 2.
Find the pdf of $Y=\frac{X}{X+2}$ and compare it to a beta distribution pdf.
}

\eoce{\qt{Joe's errors}
Joe used the linear model $y=\beta_0+\beta_1x$ with $\beta_0=0$ and $\beta_1=1$, and a variance of 1 for the errors,
and obtained the points:

\begin{tabular}{c r}
\hline
$x_i$ & $y_i$ \\
\hline
0 & -0.90 \\
1 & -0.75 \\
2 & 2.24 \\
3 & 4.17 \\
4 & 2.05 \\
5 & 4.04 \\
6 & 6.95 \\
7 & 7.74 \\
\hline
\end{tabular}

Find the true errors $\epsilon_i$ and the fitted errors $e_i$.
}

\eoce{\qt{Frances' errors}
Frances used the linear model $y=\beta_0+\beta_1x$ with $\beta_0=0$ and $\beta_1=1$, and a variance of 1 for the errors,
and obtained the points:

\begin{tabular}{c r}
\hline
$x_i$ & $y_i$ \\
\hline
0 & 0.26 \\
1 & 0.36 \\
2 & 2.23 \\
3 & 3.02 \\
4 & 2.87 \\
5 & 3.38 \\
6 & 7.39 \\
7 & 8.25 \\
\hline
\end{tabular}

Find the true errors $\epsilon_i$ and the fitted errors $e_i$.
%Solution: b_1=1.12, b_0=-0.46
}
